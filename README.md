# malware-classification-microsoft
 A comprehensive case study of malware dataset from Microsoft

Notebook is too long to render. Here's the learnings from the case study:

### Problem Description
Preventing malware attacks to a computer system by identifying whether a given file/software is malware.

Data Source: https://www.kaggle.com/c/malware-classification/data

#### Objectives
Predict the class (from the 9 label classes) of Malware for a given file

#### Constraints
1. Minimize multi-class error
2. Multi-class probability estimates
3. Fast processing and labelling of malwares (within minutes)

#### Performance metrics
1. Multi-class Log loss
2. Confustion matrix

#### Train Test Split of Data
Random split on the dataset for training, cross validation and testing with 64%, 16%, 20% of data respectively.


### EDA
Here's plots and insights from some of the most impressive EDA results.

![eda1](https://user-images.githubusercontent.com/36214903/148878683-7009d1ac-36f2-4deb-9a8b-b96269c10d9b.png)
Here's few observations from the above plots:

-Labels 1, 2, 3 are most recurring labels/classes of malwares
-Labels 8,9 are followed
-Label 4,5,7 are the least recurring labels, with fewer data points for these labels.

![image](https://user-images.githubusercontent.com/36214903/148878871-c043dc41-e953-412e-9c9c-aa2b4b46e177.png)

From the above plot, the size of the byte file might be useful in classifying the type of malware.

Using t-SNE for dimensionality reduction, we try to check if we can classify the labels in a 2-D scatter plots.
![image](https://user-images.githubusercontent.com/36214903/148879149-9f5f7cc2-3e16-4039-b5b3-d75360f657c4.png)

With a perplexity value of 50 (number of neighborhood relationships preserved), the graph does not clearly provide distinct boundaries between the different labels.

### Machine learning models
The performance of different machine learning models is measured with the precision matrix. The matrix results plotted with each trained machine learning model is shown below.

#### KNN Classification
![image](https://user-images.githubusercontent.com/36214903/148879527-1a3d16c1-de25-4a0f-a87b-f5d9613bf98b.png)

#### Logistic Regression
![image](https://user-images.githubusercontent.com/36214903/148879553-b2d9fcf6-8a5e-423d-a78b-785561246a66.png)

#### Random Forest Regression
![image](https://user-images.githubusercontent.com/36214903/148879600-fb9b2473-a283-4722-831d-c8f6278b364c.png)

#### XGB Model
![image](https://user-images.githubusercontent.com/36214903/148879744-88670adb-0933-434a-a9a1-1d7e7849359c.png)

The best performance is observed for XGB model.
